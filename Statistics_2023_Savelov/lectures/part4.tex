\section{Доверительные интервалы}

\subsection{Общие определения}

\begin{definition}
    Пусть $X$ -- выборка из неизвестного распределения $P \in \{P_\theta,\ \theta \in \Theta\}$. Пара статистик $(T_1(X), T_2(X))$ называется доверительным интервалом уровня доверия $\gamma$ для параметра $\theta \in \Theta \subset \R$, если:
    \[
        \forall \theta \in \Theta \ \ P_\theta(T_1(X) < \theta < T_2(X)) \ge \gamma
    \]

    Если равенство достигается при всех $\theta \in \Theta$, то доверительный интервал называется точным.
\end{definition}

\begin{note}
    На практике обычно используют $\gamma = 0.9,\ 0.95,\ 0.99$. Иногда удобно использовать односторонние доверительные интервалы $(-\infty, T_2(X))$ или $(T_1(X), +\infty)$. В случае многомерного $\theta \in \Theta \subset \R^k$ можно аналогично определить понятие доверительного интервала для компонент $\theta_i$ вектора $\theta = (\theta_1, \dots, \theta_k)$. И во всех случаях можно обощить понятие доверительного интервала на скалярные (действующие в $\R$) функции $\tau(\theta)$.
\end{note}

\begin{definition}
    Пусть $X$ -- выборка из неизвестного распределения $P \in \{P_\theta,\ \theta \in \Theta\}$. Множество $S(X)$ называется доверительным множеством уровня доверия $\gamma$ для параметра $\theta \in \Theta \subset \R^k$, если:
    \[
        \forall \theta \in \Theta \ \ P_\theta(\theta \in S(X)) \ge \gamma
    \]
\end{definition}

\subsection{Метод центральной статистики}

\begin{example}
    Пусть $X_1, \dots, X_n$ -- выборка из нормального распределения $N(\theta, 1),\ \theta \in \R$. Хотим построить доверительный интервал для параметра $\theta$ уровня доверия $\gamma$. Заметим, что из свойств нормального распределения:
    \[
        \ol{X} \sim N \ps{\theta, \frac{1}{n}} \Ra \sqrt{n}(\ol{X}-\theta) \sim N(0, 1)
    \]

    Обозначим $u_p$ -- $p$-квантиль $N(0, 1)$. Тогда:
    \begin{align*}
        & \forall \theta \in \Theta \ \ P \ps{u_{\frac{1-\gamma}{2}} < \sqrt{n} (\ol{X}-\theta) < u_{\frac{1+\gamma}{2}}} = \gamma
        \\
        & \forall \theta \in \Theta \ \ P \ps{-u_{\frac{1+\gamma}{2}} < \sqrt{n} (\ol{X}-\theta) < u_{\frac{1+\gamma}{2}}} = \gamma
        \\
        & \forall \theta \in \Theta \ \ P \ps{\ol{X} - \frac{u_{\frac{1+\gamma}{2}}}{\sqrt{n}} < \theta < \ol{X} + \frac{u_{\frac{1+\gamma}{2}}}{\sqrt{n}}} = \gamma
        \\
        & \ps{\ol{X} - \frac{u_{\frac{1+\gamma}{2}}}{\sqrt{n}},\ \ol{X} + \frac{u_{\frac{1+\gamma}{2}}}{\sqrt{n}}} \text{ -- точный ДИ у.д. } \gamma
    \end{align*}

    Эту конструкцию можно обобщить.
\end{example}

\begin{definition}
    Пусть $X$ -- выборка из неизвестного распределения $P \in \{P_\theta,\ \theta \in \Theta\}$. Пусть существует известная функция $G(X, \theta)$ такая, что её распределение не зависит от параметра $\theta$. Такая функция $G$ называется центральной статистикой.

    Отметим, что $G$ не является статистикой в обычном понимании слова, ибо зависит от параметра $\theta$. Но название, видимо, устоялось. То есть центральная статистика не очень центральная и не очень статистика.

    Пусть $\gamma_1, \gamma_2 \in (0, 1)$ такие, что $\gamma_2 - \gamma_1 = \gamma$. Пусть $g_1,\ g_2$ -- $\gamma_1$ и $\gamma_2$-квантили распределения $G(X, \theta)$. Тогда, аккуратно поясним ниже, выполнено:
    \[
        \forall \theta \in \Theta \ \ P_\theta(g_1 \le G(X, \theta) \le g_2) \ge \gamma_2 - \gamma_1 = \gamma
    \]

    Введём обозначение $S(X) = \{\theta \in \Theta : g_1 \le G(X, \theta) \le g_2\}$. Тогда для любого $\theta \in \Theta$ имеем $P_\theta(\theta \in S(X)) = P_\theta(g_1 \le G(X, \theta) \le g_2) \ge \gamma$, то есть $S(X)$ -- доверительное множество уровня доверия $\gamma$.
\end{definition}

\begin{note}
    Поясним здесь неравенство для квантилей, в случае непрерывных распределений оно очевидно и вырождается в равенство, иначе вызывает вопросы. По определению квантилей:
    \[
        g_\gamma = \inf \{x : F(x) \ge \gamma\} = \min \{x : F(x) \ge \gamma\}
    \]    
    Здесь $F$ -- функция распределения, инфимум достигается, так как $F$ непрерывна справа. Тогда, используя обозначение $F(x-0)$ для предела слева в точке $x$, получим:
    \begin{align*}
        & F(g_\gamma) \ge \gamma
        \\
        & F(g_\gamma - \eps) < \gamma \Ra F(g_\gamma - 0) \le \gamma
    \end{align*}
    Отсюда уже выводим неравенство:
    \[
        P_\theta(g_1 \le G(X, \theta) \le g_2) = P(G \le g_2) - P(G < g_1) = F(g_2) - F(g_1-0) \ge \gamma_2 - \gamma_1
    \]
\end{note}

\begin{note}
    Неравенство может быть строгим, например:
    
    \includegraphics[height=6cm]{images/picture2.png}
\end{note}

\begin{note}
    Квантили $g_1$ и $g_2$ можно найти в статистических таблицах, либо с помощью функций из некоторых библиотек, их вычисляющих.
\end{note}

\begin{note}
    Не всегда центральную статистику можно найти методом пристального взгляда. Для таких случаев есть полезный результат.
\end{note}

\begin{lemma}
    Пусть $X_1, \dots, X_n$ -- независимые одинаково распределённые случайные величины с функцией распределения $F(x)$, $F(x)$ непрерывна. Тогда имеет место распределение:
    \[
        G(X_1, \dots, X_n) = -\sum_{i=1}^n \ln F(X_i) \sim \Gamma \ps{1, n}
    \]
\end{lemma}

\begin{proof}~
    \begin{itemize}
        \item $F(X_i) \sim U[0, 1]$

        Если функция распределения строго монотонна, в таком случае, с учётом непрерывности, она биективно отображает $\R$ на $(0, 1)$, то доказательство простое:
        \[
            \forall y \in (0, 1) \ \ P(F(X_i) \le y) = P(X_i \le F^{-1}(y)) = F(F^{-1}(y)) = y
        \]

        И получилось, что функция распределения $F(X_i)$ совпадает с функцией распределения $U[0,1]$. В общем случае это рассуждение нужно немного пофиксить:
        \[
            \forall y \in (0, 1) \ \ P(F(X_i) \le y) = P(X_i \le \max \{x : F(x) \le y\}) = F(\max \{x : F(x) \le y\}) = y
        \]

        Максимум достигается в силу того, что функция распределения непрерывна.

        \item $-\ln U[0, 1] \sim Exp(1)$

        Пусть $\xi \sim U[0, 1]$, тогда:
        \begin{align*}
            & \forall y > 0 \ \ P(-\ln \xi \le y) = P(\xi \ge e^{-y}) = 1 - P(\xi < e^{-y}) = [e^{-y} \in (0, 1)] = 1 - e^{-y}
            \\
            & P(-\ln \xi \le y) = (1 - e^{-y}) I\{y > 0\}
        \end{align*}

        Получили в точности функцию распределения $Exp(1)$.

        \item $G(X_1, \dots, X_n) \sim \Gamma \ps{1, n}$
        
        Применим накопленные знания, воспользовавшись также формулой для суммы независимых гамма-распределений:
        \[
            G(X_1, \dots, X_n) = -\sum_{i=1}^n \ln F(X_i) \sim -\sum_{i=1}^n \ln U[0, 1] \sim \sum_{i=1}^n Exp(1) \sim \sum_{i=1}^n \Gamma(1, 1) \sim \Gamma(1, n)
        \]
    \end{itemize}
\end{proof}

\begin{corollary}
    Если $X_1, \dots, X_n$ -- выборка из неизвестного распределения $P \in \{P_\theta,\ \theta \in \Theta\}$, причём для всех $\theta \in \Theta$ функция распределения $F_\theta(x)$ непрерывна по $x$, то $G(X_1, \dots, X_n, \theta) = -\sum_{i=1}^n \ln F_\theta(X_i)$ является центральной статистикой.
\end{corollary}

\subsection{Асимптотические доверительные интервалы}

\begin{definition}
    Пусть $(X_n,\ n \ge 1)$ --  выборка неограниченного размера из неизвестного распределения $P \in \{P_\theta,\ \theta \in \Theta\}$. Последовательность пар статистик
    \[
        (T_n^{(1)}(X_1, \dots, X_n), T_n^{(2)}(X_1, \dots, X_n))
    \]
    называется асимптотическим доверительным интервалом уровня доверия $\gamma$ для неизвестного параметра $\theta$, если
    \[
        \forall \theta \in \Theta \ \ \varliminf_{n \to \infty} P_\theta(T_n^{(1)}(\dots) < \theta < T_n^{(2)}(\dots)) \ge \gamma
    \]
    Если при этом
    \[
        \forall \theta \in \Theta \ \ \lim_{n \to \infty} P_\theta(T_n^{(1)}(\dots) < \theta < T_n^{(2)}(\dots)) = \gamma
    \]
    то асимптотический доверительный интервал называют точным.
\end{definition}

\begin{note}
    Нижний предел взяли из тех соображений, что обычный предел может не существовать, в том числе тогда, когда интервал с хорошей вероятностью оценивает параметр. В случае точного АДИ уже разумно брать обычный предел.
\end{note}

\begin{note}
    Асимптотический доверительный интервал можно построить с помощью асимптотически нормальной оценки. Пусть $\hat{\theta}_n(X_1, \dots, X_n)$ -- асимптотически нормальная оценка $\theta$ с асимптотической дисперсией $\sigma^2(\theta) > 0$, то есть:
    \begin{align*}
        & \forall \theta \ \ \sqrt{n}(\hat{\theta}_n - \theta) \xrightarrow{d_\theta} N(0, \sigma^2(\theta))
        \\
        & \forall \theta \ \ \sqrt{n} \frac{\hat{\theta}_n - \theta}{\sigma(\theta)} \xrightarrow{d_\theta} N(0, 1)
    \end{align*}

    Стандартно обозначим $u_\gamma$ -- $\gamma$-квантиль $N(0, 1)$, тогда в силу сходимости по распределению и того, что у $N(0, 1)$ функция распределения всюду непрерывна, получим:
    \[
        \lim_{n \to \infty} P_\theta \ps{-u_{\frac{1+\gamma}{2}} < \sqrt{n} \frac{\hat{\theta}_n - \theta}{\sigma(\theta)} < u_{\frac{1+\gamma}{2}}} = P_\theta \ps{-u_{\frac{1+\gamma}{2}} < N(0, 1) < u_{\frac{1+\gamma}{2}}} = \gamma
    \]

    Отсюда хочется выразить асимптотический доверительный интервал для $\theta$, но есть одна проблема: знаменатель $\sigma(\theta)$ зависит от $\theta$, поэтому просто выразить не получится. Исправим это, заменив $\sigma(\theta)$ на что-то, зависящее от выборки.

    Пусть $\sigma(\theta)$ непрерывна по $\theta$. Из асимптотической нормальности оценки следует её состоятельность, поэтому $\hat{\theta}_n \xrightarrow{P_\theta} \theta$ и в силу теоремы о наследовании сходимости $\sigma(\hat{\theta}_n) \xrightarrow{P_\theta} \sigma(\theta)$. Тогда по лемме Слуцкого:
    \[
        \forall \theta \ \ \sqrt{n} \frac{\hat{\theta}_n - \theta}{\sigma(\hat{\theta}_n)} = \sqrt{n} \frac{\hat{\theta}_n - \theta}{\sigma(\theta)} \cdot \frac{\sigma(\theta)}{\sigma(\hat{\theta}_n)} \xrightarrow{d_\theta} N(0, 1) \cdot 1 = N(0, 1)
    \]

    В таком случае, в соответствии с рассуждениями выше, можем получить асимптотический доверительный интервал для $\theta$ уровня доверия $\gamma$:
    \[
        \ps{\hat{\theta}_n - u_{\frac{1+\gamma}{2}} \frac{\sigma(\hat{\theta}_n)}{\sqrt{n}},\ \hat{\theta}_n + u_{\frac{1+\gamma}{2}} \frac{\sigma(\hat{\theta}_n)}{\sqrt{n}}}
    \]
\end{note}

\subsection{Метод максимального правдоподобия}

\begin{definition}
     Пусть $X$ -- выборка размера 1 из распределения $P \in \{P_\theta,\ \theta \in \Theta\}$, а семейство распределений $\{P_\theta,\ \theta \in \Theta\}$ доминируемо относительно меры $\mu$. Тогда функцией правдоподобия называется
     \[
        f_\theta(X) = p_\theta(X)
     \]
     Здесь $p_\theta(X)$ -- плотность $P_\theta$ по мере $\mu$. Важно, что функцию правдоподобия мы рассматриваем как функцию от $\theta$ при фиксированном $X$, а не наоборот. Функция правдоподобия, разумеется, не обязана быть вероятностной мерой на $\Theta$, это просто какая-то функция.
\end{definition}

\begin{example}
    Пусть $X = (X_1, \dots, X_n)$ -- выборка из распределения $P \in \{P_\theta,\ \theta \in \Theta\}$, семейство распределений $\{P_\theta,\ \theta \in \Theta\}$ доминируемо относительно меры $\mu$. Тогда функцией правдоподобия является
    \[
        f_\theta(X) = \prod_{i=1}^n p_\theta(X_i)
    \]

    Действительно, если рассматривать $X$ как случайный вектор из многомерного распределения, то именно функция $\prod_{i=1}^n p_\theta(x_i)$ будет плотностью этого распределения, что легко выводится из теоремы Фубини-Тонелли.
\end{example}

\begin{definition}
    Пусть $X$ -- выборка с функцией правдоподобия $f_\theta(X)$. Оценкой параметра $\theta$ по методу максимального правдоподобия (ОМП) называется такая статистика $\hat{\theta}(X)$, что
    \[
        \hat{\theta}(X) = \argmax_{\theta \in \Theta} f_\theta(X)
    \]
\end{definition}

\begin{note}
    Заметим, что в определение через термин статистика сразу закладываем измеримость. Соответственно, проблемы могут заключаться в том, что $\argmax$ может не существовать, быть не единственным, и не очевидна измеримость полученной функции.
\end{note}

\begin{example}
    Пусть есть монетка с распределением $Bern(p)$, причём известно что $p$ является одним из двух значений $p_1 = \frac{1}{9}$ или $p_2 = \frac{7}{8}$. Пусть есть выборка из трёх бросков монетки, запишем в виде $110$. Тогда посмотрим на вероятность такого события в случае разных $p$:
    \begin{align*}
        & p_1 \colon P_{p_1}(110) = \frac{1}{9} \cdot \frac{1}{9} \cdot \frac{8}{9}
        \\
        & p_2 \colon P_{p_2}(110) = \frac{7}{8} \cdot \frac{7}{8} \cdot \frac{1}{8}
    \end{align*}
    Во втором случае вероятность больше, то есть вторая модель более правдоподобна, гораздо лучше предсказывает то, что произошло в реальности. В этом и заключается идея оценки максимального правдоподобия.
\end{example}

\begin{example}
    Пусть есть выборка $X_1, \dots, X_n \sim U[0, \theta]$. Правдоподобие в таком случае имеет вид:
    \[
        f_\theta(X_1, \dots, X_n) = \frac{1}{\theta^n} \prod_{i=1}^n I\{0 \le X_i \le \theta\} = \frac{1}{\theta^n} \prod_{i=1}^n I\{0 \le X_{(1)} \le X_{(n)} \le \theta\}
    \]
    Тогда ОМП есть $\hat{\theta}(X) = X_{(n)}$.
\end{example}

\begin{note}
    Ту теорию, которую будем дальше развивать в этом разделе, можно также посмотреть в книге: Леман Теория точечного оценивания.
\end{note}

\begin{definition}
    Пусть $f_\theta(X)$ -- функция правдоподобия, тогда $L_\theta(X) = \ln f_\theta(X)$ называется логарифмической функцией правдоподобия. Так как плотность принимает значение ноль на элементах выборки с нулевой вероятностью, ибо интеграл от нуля равен нулю, то можем брать логарифм.
\end{definition}

\begin{definition}
    Нам вновь понадобятся условия регулярности. На этот раз их будет больше. Опять, сначала сформулируем, потом дадим пояснения.

    \begin{itemize}
        \item[(R0)] $\{P_\theta,\ \theta \in \Theta\}$ -- параметрическое семейство распределений, доминируемое относительно меры $\mu$, $P_{\theta_1} \neq P_{\theta_2}$ при $\theta_1 \neq \theta_2$. Для всех $\theta$ обозначим $p_\theta(x)$ -- плотность $P_\theta$ относительно меры $\mu$.

        \item[(R1)] Множество $A = \{x \in \cX \colon p_\theta(x) > 0\}$ не зависит от $\theta$, $A$ называется носителем.

        \item[(R2)] $X$ есть выборка из неизвестного распределения $P \in \{P_\theta,\ \theta \in \Theta\}$.

        \item[(R3)] $\Theta$ -- открытый интервал, возможно, бесконечный.

        \item[(R4)] Функция $p_\theta(x)$ непрерывно дифференцируема по $\theta$ при всех $x \in A$.

        \item[(R5)] Функция $p_\theta(x)$ трижды непрерывно дифференцируема по $\theta$ при всех $x \in A$.

        \item[(R6)] Интеграл $\int_A p_\theta(x) \mu(dx)$ трижды дифференцируем по $\theta$ под знаком интеграла.

        \item[(R7)] Информация Фишера $i(\theta) = \E_\theta \ps{\frac{\partial}{\partial \theta} \ln p_\theta(X_1)}^2 \in (0, +\infty)$

        \item[(R8)] $\forall \theta_0 \in \Theta \ \ \exists c > 0 \ \exists H(x) \ \ \forall \theta \in (\theta_0 - c, \theta_0 + c) \ \forall x \in A$ выполнено:
        \begin{align*}
            & \md{\frac{\partial^3}{\partial \theta^3} \ln p_\theta(x)} \le H(x)
            \\
            & \E_{\theta_0} H(X_1) < \infty
        \end{align*}        
    \end{itemize}
\end{definition}

\begin{note}
    Комментарии к некоторым условиям регулярности, те пояснения, которые были к условиям регулярности для эффективных оценок, дублировать не буду:
    \begin{itemize}
        \item[(R0)] Требование $P_{\theta_1} \neq P_{\theta_2}$ при $\theta_1 \neq \theta_2$ важно в следующем смысле, например, имеем семейство распределений $Bern(\theta^2)$ и поняли, что $\theta^2 = \frac{1}{4}$, отсюда никак не сможем сделать вывод о том, чему равно $\theta$, $\frac{1}{2}$ или $-\frac{1}{2}$.

        \item[(R2)] Просто зафиксировали выборку.

        \item[(R5)] Условие (R5), конечно, сильнее условия (R4), оба нужны, потому что в разных теоремах будут предполагаться разные условия регулярности. Сначала будут использоваться (R0)-(R2), как самые базовые, в которых осмыслено работать. Затем захотим дифференцировать по $\theta$, будем жить в условиях (R0)-(R4). Затем потребуется раскладывать функцию по формуле Тейлора до некоторого порядка, будут использоваться все условия (R0)-(R8).

        \item[(R6)] Полагаю, смысл следующий, дифференцируемость подинтегральных функций знаем из предыдущего пункта, здесь утверждение в том, что существуют конечные интегралы $\int_A p_\theta(x) \mu(dx)$, $\int_A \frac{\partial}{\partial \theta} p_\theta(x) \mu(dx)$, $\int_A \frac{\partial^2}{\partial \theta^2} p_\theta(x) \mu(dx)$, $\int_A \frac{\partial^3}{\partial \theta^3} p_\theta(x) \mu(dx)$.

        \item[(R8)] Здесь Савёлов сказал, что смысл станет понятен при доказательстве соответствующей теоремы, которую потом доказывать не стал. Тем не менее, сейчас некоторую интуицию для этого условия я приведу.
    \end{itemize}    
\end{note}

\begin{reminder} (Теорема о непрерывности собственного интеграла по параметру)
	Пусть $A \subseteq \R^n$, $E \subseteq \R^m$ --- измеримые множества и задана функция $f \colon E \times A \to \R$. Если наложены следующие условия:
	\begin{enumerate}
		\item Для любого $\alpha \in A$ функция $f(x, \alpha)$ измерима на $E$
		
		\item Почти всюду на $E$ выполнено $|f(x, \alpha)| \le \phi(x)$, где $\phi \in L_1(E)$
		
		\item Почти всюду на $E$ имеет место сходимость $f(x, \alpha) \to f(x, \alpha_0)$ при $\alpha \to \alpha_0$, $\alpha \in A$
	\end{enumerate}
	Тогда интеграл $\int_E f(x, \alpha)d\mu(x)$ непрерывен в точке $\alpha_0$, то есть имеется предел:
	\[
		\lim_{\alpha \to \alpha_0} \int_E f(x, \alpha)d\mu(x) = \int_E f(x, \alpha_0)d\mu(x)
	\]
\end{reminder}

\begin{note}
    Теперь поймём смысл (R8). Выведем из похожего условия (RR8), которое будет сформулировано ниже, в условиях регулярности (R0)-(R4) и (R7) непрерывность информации Фишера $i(\theta)$.
    
    Рассмотрим произвольную точку $\theta_0 \in \Theta$, хотим в ней доказать непрерывность функции:
    \[
        i(\theta) = \E_\theta \ps{\frac{\partial}{\partial \theta} \ln p_\theta(X_1)}^2 = \int_A \ps{\frac{\partial}{\partial \theta} \ln p_\theta(x)}^2 p_\theta(x) d\mu(x)
    \]

    Рассмотрим последний интеграл в некоторой окрестности $(\theta_0 - c, \theta_0 + c)$ точки $\theta_0$, чтобы доказать непрерывность в $\theta_0$, остальные $\theta$ нам не интересны. Хотим применить для множества $A \times (\theta_0 - c, \theta_0 + c)$, рассматривается $x \in A,\ \theta \in (\theta_0 - c, \theta_0 + c)$, и функции на нём $\ps{\frac{\partial}{\partial \theta} \ln p_\theta(x)}^2 p_\theta(x)$, теорему о непрерывности собственного интеграла по параметру, тогда получим в точности то, что хотим.

    Измеримость функции $\ps{\frac{\partial}{\partial \theta} \ln p_\theta(x)}^2 p_\theta(x)$ как функции от $x$ следует из того, что интеграл по ней, то есть информация Фишера, в силу (R7) существует и конечен. Непрерывность этой функции по $\theta$ следует из того, что в силу (R4) $p_\theta(x)$ непрерывно дифференцируема по $\theta$. Осталось мажорируемость интегрируемой функцией, для этого сформулируем условие (RR8):
    \begin{itemize}
        \item[(RR8)] $\forall \theta_0 \in \Theta \ \ \exists c > 0 \ \exists H(x) \ \ \forall \theta \in (\theta_0 - c, \theta_0 + c) \ \forall x \in A$ выполнено:
        \begin{align*}
            & \ps{\frac{\partial}{\partial \theta} \ln p_\theta(x)}^2 p_\theta(x) \le H(x)
            \\
            & \int_A H(x) \mu(dx) < \infty
        \end{align*}
    \end{itemize}

    Применяем теорему о непрерывности собственного интеграла по параметру, получаем, что информация Фишера $i(\theta)$ непрерывна в произвольной точке $\theta_0$, значит, непрерывна. Запомним этот факт, он нам ещё пригодится.

    Теперь сравним условия (R8) и (RR8):
    \begin{itemize}
        \item[(R8)] $\forall \theta_0 \in \Theta \ \ \exists c > 0 \ \exists H(x) \ \ \forall \theta \in (\theta_0 - c, \theta_0 + c) \ \forall x \in A$ выполнено:
        \begin{align*}
            & \md{\frac{\partial^3}{\partial \theta^3} \ln p_\theta(x)} \le H(x)
            \\
            & \E_{\theta_0} H(X_1) < \infty
        \end{align*}

        \item[(RR8)] $\forall \theta_0 \in \Theta \ \ \exists c > 0 \ \exists H(x) \ \ \forall \theta \in (\theta_0 - c, \theta_0 + c) \ \forall x \in A$ выполнено:
        \begin{align*}
            & \ps{\frac{\partial}{\partial \theta} \ln p_\theta(x)}^2 p_\theta(x) \le H(x)
            \\
            & \int_A H(x) \mu(dx) < \infty
        \end{align*}
    \end{itemize}

    В (R8) также мажорируется некоторая функция, конкретно, третья производная логарифмического правдоподобия, но рассматривается не интеграл от мажоранты, не зависящий от $\theta$, а интеграл от мажоранты по конкретной плотности, плотности меры $P_{\theta_0}$. Соответственно, беглый просмотр того доказательства, которое в этот раз не приводилось и в котором использовалось условие (R8) показал, что это условие там использовалось совершенно не так, как применялось здесь.    
\end{note}

\begin{theorem} (Экстремальное свойство правдоподобия)
    Пусть выполнены условия регулярности (R0)-(R2). Тогда
    \[
        \forall \theta_0, \theta \in \Theta,\ \theta_0 \neq \theta \ \ P_{\theta_0}(f_{\theta_0}(X_1, \dots, X_n) > f_\theta(X_1, \dots, X_n)) \xrightarrow[n \to \infty]{} 1 
    \]
\end{theorem}

\begin{note}
    В чём смысл теоремы: настоящий параметр $\theta_0$ становится правдоподобнее любого конкурента $\theta$, если увеличивать размер выборки.
\end{note}

\begin{lemma}
    Пусть $\{\xi_n\}_{n=1}^\infty$ -- независимые одинаково распределённые случайные величины. Пусть $\E\xi_1 \in \R \cup \{-\infty, +\infty\}$. Обозначим $S_n = \xi_1 + \dots + \xi_n$. Тогда
    \[
        \frac{S_n}{n} \xrightarrow{\text{п.н.}} \E\xi_1
.    \]
\end{lemma}

\begin{proof}
     Если $\E\xi_1$ конечно, то утверждение непосредственно следует из УЗБЧ. Рассмотрим случай $\E\xi_1 = +\infty$, случай $\E\xi_1 = -\infty$ рассматривается аналогично. Возьмём срезки от случайных величин $\xi_{n, [N]} = \min(\xi_n, N)$, тогда $\xi_{n, [N]}$ -- независимые одинаково распределённые случайные величины, $-\infty < \E\xi_{1, [N]} \le N < +\infty$. В силу УЗБЧ:
     \[
        \frac{S_{n, [N]}}{n} \xrightarrow{\text{п.н.}} \E\xi_{1, [N]}
     \]

     Теперь, применяя, что $\E\xi_{1, [N]} \xrightarrow[N \to \infty]{} +\infty$, так как $\E\xi_1 = +\infty$, получим:
     \[
        \frac{S_n}{n} \ge \frac{S_{n, [N]}}{n} \xrightarrow{\text{п.н.}} \E\xi_{1, [N]} \xrightarrow[N \to \infty]{} +\infty
     \]

     \color{gray}
     В целом, уже всё доказали, формально доводится следующим образом:
     \begin{align*}
         & \forall K \in \N \ \ P\ps{\varliminf_{n \to \infty} \frac{S_n}{n} \ge K} = 1
         \\
         & P\ps{\lim_{n \to \infty} \frac{S_n}{n} = +\infty} = P\ps{\bigcap_{K=1}^\infty \varliminf_{n \to \infty} \frac{S_n}{n} \ge K} = \lim_{K \to \infty} P\ps{\varliminf_{n \to \infty} \frac{S_n}{n} \ge K} = 1
     \end{align*}

     Совсем просто сделать нельзя, так как множества для сходимости почти наверное могут отличаться для разных $N$.
     \color{black}
\end{proof}

\begin{proof} (теоремы об экстремальном свойстве правдоподобия)
    Зафиксируем параметры $\theta_0 \neq \theta$. Можем считать, что все элементы выборки $X_1, \dots, X_n \in A$, т.е. имеют ненулевую плотность. Имеем на это право, ибо такое выполнено почти наверное для всех $P \in \{P_\theta,\ \theta \in \Theta\}$:
    \[
        P(\forall i \in \N \ X_i \in A) = P\ps{\bigcap_{i=1}^\infty \{X_i \in A\}} = \lim_{n \to \infty} P\ps{\bigcap_{i=1}^n \{X_i \in A\}} = \lim_{n \to \infty} 1 = 1
    \]
    
    Хотим доказать, что $P_{\theta_0}(f_{\theta_0}(X_1, \dots, X_n) > f_\theta(X_1, \dots, X_n)) \xrightarrow[n \to \infty]{} 1$. Можем переписать неравенство для функций правдоподобия в виде, к которому можно будет применить доказанную только что лемму об обобщённом УЗБЧ, здесь пользуемся тем, что плотность не равна нулю:
    \begin{align*}
        & f_{\theta_0}(X_1, \dots, X_n) > f_\theta(X_1, \dots, X_n)
        \\
        & \Updownarrow
        \\
        & \ln \frac{f_\theta(X_1, \dots, X_n)}{f_{\theta_0}(X_1, \dots, X_n)} < 0
        \\
        & \Updownarrow
        \\
        & \frac{1}{n} \sum_{i=1}^n \ln \frac{f_\theta(X_i)}{f_{\theta_0}(X_i)} < 0
    \end{align*}

    Далее хотим показать, что $-\infty \le \E_{\theta_0} \ln \frac{f_\theta(X_1)}{f_{\theta_0}(X_1)} < 0$. Если это так, то всё доказано, Савёлов это подробнее не обосновывал, мы распишем аккуратно, действительно, по лемме:
    \begin{align*}
        & P_{\theta_0}\ps{\lim_{n \to \infty} \frac{1}{n} \sum_{i=1}^n \ln \frac{f_\theta(X_i)}{f_{\theta_0}(X_i)} = \E_{\theta_0} \ln \frac{f_\theta(X_1)}{f_{\theta_0}(X_1)}} = 1
        \\
        & P_{\theta_0}\ps{\lim_{n \to \infty} \frac{1}{n} \sum_{i=1}^n \ln \frac{f_\theta(X_i)}{f_{\theta_0}(X_i)} < 0} = 1
        \\
        & P_{\theta_0}\ps{\exists N \ \forall n \ge N \ \ \frac{1}{n} \sum_{i=1}^n \ln \frac{f_\theta(X_i)}{f_{\theta_0}(X_i)} < 0} = 1
        \\
        & P_{\theta_0}\ps{\bigcup_{N=1}^\infty \bigcap_{n=N}^\infty \set{\frac{1}{n} \sum_{i=1}^n \ln \frac{f_\theta(X_i)}{f_{\theta_0}(X_i)} < 0}} = 1
    \end{align*}

    И отсюда получаем требуемую предельную вероятность: 
    \begin{multline*}
        \lim_{n \to \infty} P_{\theta_0}(f_{\theta_0}(X_1, \dots, X_n) > f_\theta(X_1, \dots, X_n)) = \lim_{n \to \infty} P_{\theta_0} \ps{\frac{1}{n} \sum_{i=1}^n \ln \frac{f_\theta(X_i)}{f_{\theta_0}(X_i)} < 0} \ge
        \\
        \ge \lim_{N \to \infty} P_{\theta_0} \ps{\bigcap_{n=N}^\infty \set{\frac{1}{n} \sum_{i=1}^n \ln \frac{f_\theta(X_i)}{f_{\theta_0}(X_i)} < 0}} = P_{\theta_0}\ps{\bigcup_{N=1}^\infty \bigcap_{n=N}^\infty \set{\frac{1}{n} \sum_{i=1}^n \ln \frac{f_\theta(X_i)}{f_{\theta_0}(X_i)} < 0}} = 1
    \end{multline*}

    Осталось доказать, что $\E_{\theta_0} \ln \frac{f_\theta(X_1)}{f_{\theta_0}(X_1)} < 0$. Для этого вспомним факт из математического анализа: $\ln(1+x) \le x$ при всех $x > -1$, равенство достигается только при $x = 0$. Дальнейшее доказательство будет состоять из серии хитрых и не очень преобразований:
    \begin{multline*}
        \E_{\theta_0} \ln \frac{f_\theta(X_1)}{f_{\theta_0}(X_1)} = \int_A \ln \frac{p_\theta(x)}{p_{\theta_0}(x)} p_{\theta_0}(x) \mu(dx) = \int_A \ln \ps{1 + \frac{p_\theta(x)}{p_{\theta_0}(x)} - 1} p_{\theta_0}(x) \mu(dx) \le
        \\
        \le \int_A \ps{\frac{p_\theta(x)}{p_{\theta_0}(x)} - 1} p_{\theta_0}(x) \mu(dx) = \int_A \ps{p_\theta(x) - p_{\theta_0}(x)} \mu(dx) = 1 - 1 = 0
    \end{multline*}

    Пока доказали нестрогую версию неравенства, $\E_{\theta_0} \ln \frac{f_\theta(X_1)}{f_{\theta_0}(X_1)} \le 0$, но равенство может быть лишь в случае $\frac{p_\theta(x)}{p_{\theta_0}(x)} - 1 = 0 \ \mu\text{-п.н.} \Lra p_\theta(x) = p_{\theta_0}(x) \ \mu\text{-п.н.}$, то есть $P_{\theta_0} = P_\theta$, тогда $\theta = \theta_0$ в силу одного из условий регулярности, что невозможно в силу выбора $\theta \neq \theta_0$.
\end{proof}

\begin{corollary}
    В условиях регулярности (R0)-(R2), если $\Theta$ -- конечное множество, то есть $\Theta = \{\theta_1, \dots, \theta_s\}$, то оценка максимального правдоподобия существует, единственна с вероятностью, стремящейся к 1, при этом она состоятельна.
\end{corollary}

\begin{proof}
    Пусть $X = (X_1, \dots, X_n)$ -- выборка из распределения $P_{\theta_k}$, в силу теоремы об экстремальном свойстве правдоподобия и конечности множества $\Theta$ выполнено:
    \[
        P_{\theta_k}\ps{f_{\theta_k}(X) > f_{\theta_m}(X) \ \forall m \neq k} \xrightarrow[n \to \infty]{} 1
    \]

    Договоримся, что если на нескольких $\theta_i$ правдоподобие одинаково, то в качестве оценки максимального правдоподобия $\hat{\theta}(X)$ возьмём из них $\theta_i$ с наименьшим номером $i$. Докажем измеримость полученной функции от выборки, отсюда получим существование ОМП. Для этого проверим измеримость множеств $\{X \colon \hat{\theta}(X) = \theta_i\}$. Действительно:
    \[
        \{X \colon \hat{\theta}(X) = \theta_i\} = \bigcap_{j=1}^{i-1} \{X \colon f_{\theta_j}(X) < f_{\theta_i}(X)\} \cap \bigcap_{j=i+1}^s \{X \colon f_{\theta_j}(X) \le f_{\theta_i}(X)\}
    \]

    Так как функции правдоподобия измеримы, то все множества из пересечений справа измеримы, следовательно, множество слева тоже измеримо. Единственность с вероятностью, стремящейся к единице, следует из того, что со стремящейся к единице вероятностью правдоподобие для $\theta_k$ будет строго больше остальных.

    Состоятельность тоже проверяется без особого труда:
    \[
        \forall \eps > 0 \ \ P\ps{\md{\hat{\theta}(X)-\theta_k} > \eps} \le P\ps{\hat{\theta}(X) \neq \theta_k} \xrightarrow[n \to \infty]{} 0
    \]   
\end{proof}

\begin{definition}
    Пусть выполнены условия регулярности (R0)-(R4). Уравнением правдоподобия называется уравнение относительно $\theta$ в одной из двух следующих эквивалентых форм:
    \[
        \frac{\partial \ln f_\theta(X)}{\partial \theta} = 0 \Lra \frac{\partial f_\theta(X)}{\partial \theta} = 0
    \]
\end{definition}

\begin{note}
    В формулировку следующей теоремы в деталях лучше вникнуть после того, как будет изучено её доказательство, она так воспринимается гораздо проще.
\end{note}

\begin{note}
    В следующей теореме нам потребуется внешняя мера. Она нам будет нужна лишь как аналог меры, который гарантированно существует для всех множеств, не обязательно измеримых, но для общей картины напомним, что это.

    Пусть $\cA$ -- алгебра подмножеств $X$, $\mu$ -- счётно-аддитивная мера на ней, тогда для всех множеств $E \subset X$ определим внешнюю меру $\mu^*$ как:
    \[
        \mu^*(E) = \inf \set{\sum_{j=1}^\infty \mu(A_j) \colon A_j \in \cA,\ E \subset \bigcup_{j=1}^\infty A_j}
    \]

    Напомним свойства внешней меры:
    \begin{enumerate}
        \item $\mu^*(E) = \mu(E) \ \ \forall E \in \cA$
        \item $\mu^*(A) \le \mu^*(B) \ \ \forall A \subset B$
        \item $\mu^*\ps{\bigcup_{n=1}^\infty E_n} \le \sum_{n=1}^\infty \mu^*(E_n)$
    \end{enumerate}

    Далее эта конструкция использовалась следующим образом: из свойств 1 и 3 следует, что $\mu(X) = \mu^*(X) \le \mu^*(E) + \mu^*(X \setminus E)$, исходя из этого множество $E$ называлось измеримым, если $\mu(X) = \mu^*(E) + \mu^*(X \setminus E)$, это давало продолжение меры $\mu$ на некоторую $\sigma$-алгебру подмножеств $X$.
\end{note}

\begin{theorem} (Аналог состоятельности ОМП)
    Пусть выполнены условия регулярности (R0)-(R4). Пусть элементы выборки $X$ имеют распределение $P_{\theta_0}$. Тогда существует отображение $\hat{\theta}_n(X_1, \dots, X_n, \theta_0)$ со значениями в $\Theta$, такое, что:
    \begin{align*}
        & (P_{\theta_0})^*(\hat{\theta}_n \text{ не решение уравнения правдоподобия}) \xrightarrow[n \to \infty]{} 0
        \\
        & \forall \eps > 0 \ \ (P_{\theta_0})^*(|\hat{\theta}_n - \theta_0| \ge \eps) \xrightarrow[n \to \infty]{} 0
    \end{align*}
\end{theorem}

\begin{proof}~
    \begin{itemize}
        \item Сначала разберёмся с тем, что за зверь такой $\hat{\theta}_n(X_1, \dots, X_n, \theta_0)$. Идея состоит в следующем: решений уравнения правдоподобия может быть много, оценка максимального правдоподобия, если она есть, также является решением этого уравнения, но обратное неверно. Хотим посмотреть, есть ли среди решений что-то хорошее, если знаем ответ -- истинное значение параметра $\theta_0$.

        Определим $\hat{\theta}_n$. Зафиксируем выборку $X = (X_1, \dots, X_n)$ из множества $A$, можем так считать, так как то, что вся выборка попала во множество $A$ выполнено с единичной вероятностью.

        Если у уравнения правдоподобия $\frac{\partial \ln f_\theta(X)}{\partial \theta} = 0$ есть хотя бы один корень $\theta$, то выберем ближайший к $\theta_0$ корень и обзовём его $\hat{\theta}_n(X_1, \dots, X_n, \theta_0)$. Допускается, что этим корнем может быть сам $\theta_0$. Существование ближайшего осмыслено, ибо в силу непрерывной дифференцируемости $f_\theta(X)$ предел последовательности корней также является корнем, так что если ближайшего нет, то $\theta_0$ сам является корнем, то есть ближайший всё-таки есть.

        Если у уравнения правдоподобия нет корней, то определим $\hat{\theta}_n(X_1, \dots, X_n, \theta_0) = \theta_0$. Таким образом, получилась некоторая функция $\hat{\theta}_n$. Вообще не факт, что она измеримая, поэтому нам и понадобится внешняя мера $(P_{\theta_0})^*$.

        \item Теперь зафиксируем $\eps > 0$ такое, что $(\theta_0 - \eps, \theta_0 + \eps) \subset \Theta$, в силу открытости $\Theta$ можем так сделать. Рассмотрим $S_n(\theta_0, \eps) = \{X \colon f_{\theta_0-\eps}(X) < f_{\theta_0}(X) > f_{\theta_0+\eps}(X)\}$. Чем это множество интересно: на нём во внутренней точке $(\theta_0 - \eps, \theta_0 + \eps)$ будет достигаться локальный максимум в силу непрерывности функции правдоподобия $f_\theta(X)$, тогда в окрестности $(\theta_0 - \eps, \theta_0 + \eps)$ точки $\theta_0$ будет решение уравнения правдоподобия.

        \includegraphics{images/picture3.png}

        Итак, зафиксировали $\eps > 0$ такое, что $(\theta_0 - \eps, \theta_0 + \eps) \subset \Theta$, рассматриваем множество $S_n(\theta_0, \eps) = \{X \colon f_{\theta_0-\eps}(X) < f_{\theta_0}(X) > f_{\theta_0+\eps}(X)\}$. В силу условий регулярности (R0)-(R2) и результата теоремы об экстремальном свойстве правдоподобия выполнено $P_{\theta_0}(S_n(\theta_0, \eps)) \xrightarrow[n \to \infty]{} 1$. При этом в силу уже проведённых рассуждений для $X \in S_n(\theta_0, \eps)$ на $(\theta_0 - \eps, \theta_0 + \eps)$ существует локальный максимум, то есть корень уравнения правдоподобия, правда, не обязательно один и не обязательно там нет локальных минимумов. Но в любом случае выполнено:
        \begin{align*}
            & \forall X \in S_n(\theta_0, \eps) \ \ \hat{\theta}_n(X_1, \dots, X_n, \theta_0) \text{ -- корень уравнения правдоподобия}
            \\
            & \forall X \in S_n(\theta_0, \eps) \ \ \hat{\theta}_n(X_1, \dots, X_n, \theta_0) \in (\theta_0 - \eps, \theta_0 + \eps)
            \\
            & P_{\theta_0}(S_n(\theta_0, \eps)) \xrightarrow[n \to \infty]{} 1
        \end{align*}

        Применим неравенство для внешних мер, переход к внешним мерам происходит потому, что не убеждены в измеримости соответствующих множеств, получим то, что требовалось.
    \end{itemize}
\end{proof}

\begin{note}
    Для практики этот результат имеет несколько проблем. Во-первых, не убеждены в измеримости $\hat{\theta}_n$, во-вторых, если корней уравнения правдоподобия несколько, то не можем понять, какой из них брать, так как не знаем $\theta_0$, в-третьих, не факт, что корень уравнения правдоподобия максимум, тем более, даже если локальный максимум, не обязательно глобальный. Но в некоторых частных случаях таких проблем не возникает.
\end{note}

\begin{corollary}
    Пусть выполнены условия регулярности (R0)-(R4) и для всех $n$ для всех $X_1, \dots, X_n$ существует и единственно решение $\hat{\theta}_n(X)$ уравнения правдоподобия, являющееся измеримой функцией от выборки $X$. Тогда $\hat{\theta}_n(X)$ -- состоятельная оценка $\theta$, и с вероятностью $\to 1$ $\hat{\theta}_n$ является ОМП.
\end{corollary}

\begin{proof}~
    \begin{itemize}
        \item В силу существования, единственности и измеримости решения уравнения правдоподобия, проблем с определением и измеримостью $\hat{\theta}_n(X_1, \dots, X_n)$ при неизвестном параметре $\theta_0$ не возникает. Тогда результат доказанной только что теоремы можно записать в виде, из которого мгновенно следует состоятельность:
        \[
            \forall \eps > 0 \ \ P_{\theta_0}(|\hat{\theta}_n(X) - \theta_0| \ge \eps) \xrightarrow[n \to \infty]{} 0
        \]

        \item Осталось обосновать ОМП. Как и в самой теореме, с вероятностью, стремящейся к единице, выполнено $f_{\theta_0-\eps}(X) < f_{\theta_0}(X) > f_{\theta_0+\eps}(X)$ для $(\theta_0 - \eps, \theta_0 + \eps) \subset \Theta$, тогда во внутренней точке $\theta_1 \in (\theta_0 - \eps, \theta_0 + \eps)$ достигается локальный максимум, и $\theta_1$ является решением уравнения правдоподобия. Тогда выполнено $\hat{\theta}_n(X) = \theta_1$.

        Если $\theta_1$ не является глобальным максимумом $f_\theta(X)$, то есть существует $\theta_2 \in \Theta$ такая, что $f_{\theta_2}(X) \ge f_{\theta_1}(X)$, без ограничения общности $\theta_1 < \theta_2$, тогда, так как $\theta_1$ -- локальный максимум, то $\exists \theta_3 \in (\theta_1, \theta_2)$, в которой $f_{\theta_1}(X) \ge f_{\theta_3}(X) \le f_{\theta_2}(X)$, тогда на $(\theta_1, \theta_2)$ есть ещё одно решение уравнения правдоподобия, что противоречит его единственности.
    \end{itemize}
\end{proof}

\begin{theorem} (б/д)
    В условиях регулярности (R0)-(R8) любая состоятельная последовательность оценок $\hat{\theta}_n(X)$, являющихся решениями уравнения правдоподобия, удовлетворяет соотношению:
    \[
        \forall \theta \in \Theta \ \ \sqrt{n}(\hat{\theta}_n(X) - \theta) \xrightarrow{d_\theta} N\ps{0, \frac{1}{i(\theta)}}
    \]
\end{theorem}

\begin{note}
    Здесь $i(\theta)$ -- информация Фишера. То, что она стоит в знаменателе асимптотической дисперсии, логично, ибо, неформально, чем больше информации, тем меньше дисперсия.
\end{note}

\begin{note}
    Неформально утверждение теоремы можем переписать в таком виде:
    \[
        \forall \theta \in \Theta \ \ \hat{\theta}_n(X) \approx N\ps{\theta, \frac{1}{n i(\theta)}} = N\ps{\theta, \frac{1}{I_X(\theta)}}
    \]

    Отсюда можем увидеть аналогию эффективных оценок и оценок максимального правдоподобия: в обоих случаях дисперсия равна $\frac{1}{I_X(\theta)}$, в обоих случаях, для ОМП соответствующий результат скоро сформулируем, все остальные рассматриваемые оценки имеют дисперсию не лучше $\frac{1}{I_X(\theta)}$.
\end{note}

\begin{corollary} (Асимптотическая нормальность ОМП)
    В условиях регулярности (R0)-(R8), если $\forall n \ \forall X_1, \dots, X_n$ существует единственное решение $\hat{\theta}_n(X)$ уравнения правдоподобия, являющееся измеримой функцией выборки, то $\hat{\theta}_n(X)$ является асимптотически нормальной оценкой $\theta$ с асимптотической дисперсией $\frac{1}{i(\theta)}$.
\end{corollary}

\begin{proof}
    Мгновенно получается из последней теоремы и следствия предпоследней теоремы.
\end{proof}

\begin{theorem} (Бахадур, б/д)
    Пусть выполнены условия регулярности (R0)-(R8) и $\hat{\theta}_n(X)$ -- асимптотически нормальная оценка параметра $\theta$ с асимптотической дисперсией $\sigma^2(\theta)$, причём $\sigma(\theta)$ -- непрерывная функция. Тогда $\forall \theta \in \Theta \ \ \sigma^2(\theta) \ge \frac{1}{i(\theta)}$.
\end{theorem}

\begin{note}
    Это тот самый обещанный результат про то, что ОМП имеют наименьшую асимптотическую дисперсию.
\end{note}

\begin{note}
    Если не требовать непрерывность $\sigma(\theta)$, то неравенство $\sigma^2(\theta) \ge \frac{1}{i(\theta)}$ будет выполено с точностью до множества меры нуль. Хороший вопрос, что такое множество меры нуль по $\theta$, как показал беглый просмотр статьи Бахадура, это классическая мера Лебега на $\Theta \subset \R$.
\end{note}

\begin{corollary}
    В условиях регулярности (R0)-(R8), если $\forall n \ \forall X_1, \dots, X_n$ существует единственное решение $\hat{\theta}_n(X)$ уравнения правдоподобия, являющееся измеримой функцией выборки, то $\hat{\theta}_n(X)$ не хуже любой другой оценки в асимптотическом подходе в классе асимптотических оценок с непрерывной асимптотической дисперсией.
\end{corollary}

\begin{note}
    В общем и целом, результат непосредственно следует из уже доказанного, за исключением одного факта: с чего мы взяли, что сама асимптотическая дисперсия ОМП $\frac{1}{i(\theta)}$ непрерывна? Беглый анализ показал, что я не умею это выводить без добавленного мною в одном замечании условия регулярности (RR8), а если его предполагать, то доказательство непрерывности есть в том же замечании.
\end{note}

\begin{definition}
    Пусть выполнены условия регулярности (R0)-(R8). Если для оценки $\hat{\theta}(X)$ параметра $\theta$ выполнено
    \[
        \sqrt{n}(\hat{\theta}_n(X) - \theta) \xrightarrow{d_\theta} N\ps{0, \frac{1}{i(\theta)}}
    \]
    то $\hat{\theta}_n(X)$ называют асимптотически эффективной оценкой параметра $\theta$.
\end{definition}

\begin{note}
    Теперь несложный факт про то, что эффективные оценки, именно эффективные, из неравенства Рао-Крамера, являются оценками максимального правдоподобия. Неформально, суть в том, что если эффективность была до предела, то и в пределе получится что-то хорошее.
\end{note}

\begin{proposition}
    Пусть выполнены условия регулярности из неравенства Рао-Крамера, $\hat{\theta}(X)$ -- эффективная оценка параметра $\theta$, и в критерии эффективности равенство $\hat{\theta}(X) - \tau(\theta) = c(\theta) U_\theta(X)$ выполнено для всех $X$ из носителя $A$ и для всех $\theta$ (а не $P_\theta$-п.н., как там доказывалось). $X$ из носителя $A$, имеется в виду, что все $X_i \in A$. Тогда $\hat{\theta}(X)$ -- оценка максимального правдоподобия.
\end{proposition}

\begin{proof}
    Из условий теоремы равенство из критерия эффективности выполнено всюду, вклад выборки распишем по определению:
    \[
        \hat{\theta}(X) - \theta = c(\theta) \frac{\partial}{\partial \theta} \ln f_{\theta}(X),\ \ c(\theta) = \frac{1}{I_X(\theta)} > 0
    \]

    Тогда при всех $\theta < \hat{\theta}(X)$ $\frac{\partial}{\partial \theta} \ln f_{\theta}(X) > 0$, при $\theta > \hat{\theta}(X)$ $\frac{\partial}{\partial \theta} \ln f_{\theta}(X) < 0$. То есть логарифм правдоподобия, как и само правдоподобие, $\ln f_\theta(X)$ возрастает до $\hat{\theta}(X)$ и убывает после $\hat{\theta}(X)$, то есть в точке $\hat{\theta}(X)$ достигается глобальный максимум, что и означает, что оценка является ОМП.
\end{proof}