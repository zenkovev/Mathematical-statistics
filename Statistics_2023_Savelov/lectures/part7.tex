\section{Проверка статистических гипотез}

\subsection{Коэффициенты корреляции}

\begin{note}
    Пусть $X = (X_1, \dots, X_n)$ и $Y = (Y_1, \dots, Y_n)$ -- две выборки одинакового размера, причём случайные векторы $(X_1, Y_1), \dots, (X_n, Y_n)$ независимы и одинаково распределены. Хотим проверить гипотезу $H_0 \colon X_1 \indep Y_1$, то есть, что выборки независимы. Её можно переписать в эквивалентном виде: $H_0 \colon F_{X_1, Y_1}(t, s) = F_{X_1}(t) F_{Y_1}(s) \ \forall t, s \in \R$. Так как независимость проверять достаточно тяжело, в основном будем проверять более слабое предположение о том, что выборки нескоррелированы, то есть $\cov(X_1, Y_1) = 0$. Далее будем считать, что $0 < \E X_1^2 < \infty$, $0 < \E Y_1^2 < \infty$, это нужно для того, чтобы корректно насчитывать дисперсию, ковариацию и коэффициент корреляции. 
\end{note}

\subsubsection{Коэффициент корреляции Пирсона}

\begin{note}
    Идея состоит в следующем: хотим проверить нескоррелированность выборок $X_1, \dots, X_n$ и $Y_1, \dots, Y_n$, то есть, что $\cov(X_1, Y_1) = 0$. Посчитать реальное значение ковариации мы не можем, зато можем посчитать его выборочный аналог. Но так как $\cov(X_1, Y_1)$ принимает значения от $-\infty$ до $+\infty$, то насчитанное ненулевое значение на выборке даст мало информации, а ровно нулевое значение получится с очень небольшой вероятностью. Поэтому заменим ковариацию на её нормированный аналог -- коэффициент корреляции $\corr(X_1, Y_1)$, он уже принимает значения от $-1$ до $1$, так что такой проблемы не возникает.
\end{note}

\begin{definition}
    Коэффициентом корреляции Пирсона называется величина
    \[
        \hat{\rho} = \frac{\frac{1}{n} \sum_{i=1}^n (X_i - \ol{X})(Y_i-\ol{Y})}{\sqrt{\frac{1}{n} \sum_{i=1}^n (X_i-\ol{X})^2} \sqrt{\frac{1}{n} \sum_{i=1}^n (Y_i-\ol{Y})^2}} = \frac{\sum_{i=1}^n (X_i - \ol{X})(Y_i-\ol{Y})}{\sqrt{\sum_{i=1}^n (X_i-\ol{X})^2 \sum_{i=1}^n (Y_i-\ol{Y})^2}}
    \]
\end{definition}

\begin{note}
    Как видно из первого равенства, это выборочный аналог обычного коэффициента корреляции.
\end{note}

\begin{proposition}
    \[
        \hat{\rho} \xrightarrow{\text{п.н.}} \corr(X_1, Y_1) = \frac{\cov(X_1, Y_1)}{\sqrt{DX_1 DY_1}}
    \]
\end{proposition}

\begin{proof}
    Сначала приведём формулы к более удобному виду:
    \begin{align*}
        & DX_1 = \E(X_1-\E X_1)^2 = \E X_1^2 - 2 (\E X_1)^2 + (\E X_1)^2 = \E X_1^2 - (\E X_1)^2 &
        \\
        & \cov(X_1, Y_1) = \E[(X_1 - \E X_1)(Y_1 - \E Y_1)] =
        \\
        & \hspace{1cm} = \E(X_1 Y_1) - 2\E X_1 \E Y_1 + \E X_1 \E Y_1 = \E(X_1 Y_1) - \E X_1 \E Y_1
        \\
        & \frac{1}{n} \sum_{i=1}^n (X_i-\ol{X})^2 = \frac{1}{n} \sum_{i=1}^n X_i^2 - \frac{1}{n} 2 \ol{X} \sum_{i=1}^n X_i + \frac{1}{n} \sum_{i=1}^n \ol{X}^2 = \ol{X^2} - 2\ol{X}^2 + \ol{X}^2 = \ol{X^2} - \ol{X}^2
        \\
        & \frac{1}{n} \sum_{i=1}^n (X_i - \ol{X})(Y_i-\ol{Y}) = \frac{1}{n} \sum_{i=1}^n X_i Y_i - \frac{1}{n} \ol{X} \sum_{i=1}^n Y_i - \frac{1}{n} \ol{Y} \sum_{i=1}^n X_i + \frac{1}{n} \sum_{i=1}^n \ol{X} \cdot \ol{Y} =
        \\
        & \hspace{1cm} = \ol{XY} - 2 \ol{X} \cdot \ol{Y} + \ol{X} \cdot \ol{Y} = \ol{XY} - \ol{X} \cdot \ol{Y}
    \end{align*}

    Осталось применить УЗБЧ и теорему о наследовании сходимости:
    \begin{align*}
        & \frac{1}{n} \sum_{i=1}^n (X_i-\ol{X})^2 \xrightarrow{\text{п.н.}} DX_1
        \\
        & \frac{1}{n} \sum_{i=1}^n (Y_i-\ol{Y})^2 \xrightarrow{\text{п.н.}} DY_1
        \\
        & \frac{1}{n} \sum_{i=1}^n (X_i - \ol{X})(Y_i-\ol{Y}) \xrightarrow{\text{п.н.}} \cov(X_1, Y_1)
        \\
        & \hat{\rho} \xrightarrow{\text{п.н.}} \corr(X_1, Y_1)
    \end{align*}
\end{proof}

\begin{note}
    В общем случае из нескоррелированности не следует независимость, однако такое следствие есть, если выборки имеют нормальное распределение. Оказывается, что хороший теоретический результат для коэффициента корреляции Пирсона тоже связан с нормальными выборками.
\end{note}

\begin{theorem} (б/д)
    Пусть $n > 2$, $X, Y$ -- две независимые выборки размера $n$, имеющие нормальное распределение. Тогда знаем, что следующая статистика имеет распределение Стьюдента:
    \[
        T = \frac{\hat{\rho} \sqrt{n-2}}{\sqrt{1 - \hat{\rho}^2}} \sim T_{n-2}
    \]
\end{theorem}

\begin{note}
    Тогда для проверки гипотезы о независимости нормальных выборок размера хотя бы $2$ разумно использовать критерий $S = \{|T| > u_{1-\gamma}\}$, где $u_\gamma$ -- $\gamma$-квантиль распределения Стьюдента $T_{n-2}$.
\end{note}

\subsubsection{Коэффициент корреляции Спирмена}

\begin{note}
    Коэффициент корреляции Пирсона крайне неустойчив к наличию выбросов, что следует ожидать, так как выбросы могут сильно влиять на значение среднего, дисперсии и других насчитываемых величин. Одним из путей решения этой проблемы может быть замена значения элемента выборки на его ранг, то есть порядковый номер в отсортированной выборке.
\end{note}

\begin{definition}
    Пусть $X_1, \dots, X_n$ -- выборка из непрерывного распределения. Упорядочим элементы выборки по возрастанию. Номера, которые получили элементы выборки при таком упорядочивании, назовём рангами $R_1, \dots, R_n$, то есть:
    \[
        R(X_i) = R_i = j \Lra X_{(j)} = X_i
    \]
\end{definition}

\begin{note}
    Требование непрерывности распределения нужно ровно по одной причине: чтобы с вероятностью 1 все элементы выборки были различны. В целом, с совпадением значений элементов выборки можно справиться: способ первый: среди совпадающих значений рандомно распределить допустимые ранги, способ второй: совпадающим значениям присвоить средний ранг из допустимых, например:
    \begin{align*}
        & \text{Способ 1: 4 2 3 4 5 1 1 2 5 5 } \to \text{ 7 3 5 6 8 2 1 4 9 10}
        \\
        & \text{Способ 2: 4 2 3 4 5 1 1 2 5 5 } \to \text{ 6.5 3.5 5 6.5 9 1.5 1.5 3.5 9 9}
    \end{align*}
\end{note}

\begin{note}
    Отметим простые свойства введённых рангов:
    \begin{enumerate}
        \item $(R_1, \dots, R_n) \in S_n$ -- перестановка множества $(1, \dots, n)$
        \item $P(R_1 = r_1, \dots, R_n = r_n) = \frac{1}{n!} \ \ \forall (r_1, \dots, r_n) \in S_n$
    \end{enumerate}
    Действительно, в случае выборок из непрерывных распределений: если будем бороться с совпадающими значениями первым способом, то первое свойство будет выполнено автоматически, на второе свойство событие совпадения значений влияния не оказывает, так как имеет нулевую вероятность, второе свойство следует из того, что элементы выборки независимы и одинаково распределены.
\end{note}

\begin{note}
    Пусть $Y_1, \dots, Y_n$ -- тоже выборка из непрерывного распределения, аналогично введём ранги $S_1, \dots, S_n$.
\end{note}

\begin{definition}
    Коэффициентом корреляции Спирмена называется величина
    \[
        \rho_S = \frac{\sum_{i=1}^n (R_i - \ol{R})(S_i-\ol{S})}{\sqrt{\sum_{i=1}^n (R_i-\ol{R})^2 \sum_{i=1}^n (S_i-\ol{S})^2}}
    \]
\end{definition}

\begin{note}
    Заметим несколько фактов, которые позволят упростить запись коэффициента Спирмена. Для этого воспользуемся комбинаторной формулой $\sum_{k=1}^n k^2 = \frac{n(n+1)(2n+1)}{6}$. Получим:
    \begin{align*}
        & \ol{R} = \frac{1}{n} \sum_{i=1}^n R_i = \frac{1}{n} \sum_{j=1}^n j = \frac{1}{n} \frac{n(n+1)}{2} = \frac{n+1}{2}
        \\
        & \sum_{i=1}^n (R_i-\ol{R})^2 = \sum_{i=1}^n \ps{R_i-\frac{n+1}{2}}^2 = \sum_{j=1}^n \ps{j-\frac{n+1}{2}}^2 =
        \\
        & \hspace{1cm} = \sum_{j=1}^n j^2 - 2 \frac{n+1}{2} \sum_{j=1}^n j + n \ps{\frac{n+1}{2}}^2 = \frac{n(n+1)(2n+1)}{6} - \frac{n(n+1)^2}{2} + \frac{n(n+1)^2}{4} =
        \\
        & \hspace{1cm} = \frac{n(n+1)}{2} \ps{\frac{2n+1}{3} - \frac{n+1}{2}} = \frac{n(n+1)}{2} \frac{n-1}{6} = \frac{n^3-n}{12}
        \\
        & \ol{S} = \frac{n+1}{2},\ \sum_{i=1}^n (S_i-\ol{S})^2 = \frac{n^3-n}{12}
    \end{align*}
\end{note}

\begin{definition}
    Введём ещё одно полезное обозначение. Рассмотрим пары рангов выборок $(R_1, S_1), \dots, (R_n, S_n)$ и упорядочим их по первой координате, получим отсортированный вид $(1, T_1), \dots, (n, T_n)$, иными словами, обозначим $T_i$ как значение второго элемента $i$-й пары после сортировки. Можно также записать через $R_i = k \Lra S_i = T_k$.
\end{definition}

\begin{note}
    $(T_1, \dots, T_n) \in S_n$, то есть перестановка элементов $(1, \dots, n)$. В случае справедливости гипотезы $H_0$ о том, что выборки $X_1, \dots, X_n$ и $Y_1, \dots, Y_n$ независимы, $(T_1, \dots, T_n)$ является случайной перестановкой в смысле:
    \[
        P(T_1 = r_1, \dots, T_n = r_n) = \frac{1}{n!} \ \ \forall (r_1, \dots, r_n) \in S_n
    \]
\end{note}

\begin{proposition}
    Коэффициент корреляции Спирмена можно записать в следующих эквивалентных видах:
    \begin{enumerate}
        \item $\rho_S = \frac{12}{n^3-n} \sum\limits_{k=1}^n \ps{k - \frac{n+1}{2}} \ps{T_k -\frac{n+1}{2}}$

        \item $\rho_S = 1 - \frac{6}{n^3-n} \sum\limits_{k=1}^n (R_k-S_k)^2 = 1 - \frac{6}{n^3-n} \sum\limits_{k=1}^n (k-T_k)^2$

        \item $\rho_S = 1 - \frac{12}{n^3-n} \sum\limits_{i<j} (j-i) I\{T_i > T_j\}$
    \end{enumerate}
\end{proposition}

\begin{proof}~
    \begin{enumerate}
        \item Воспользуемся формулами, полученными в одном из последних замечаний:
        \begin{multline*}
            \rho_S = \frac{\sum_{i=1}^n (R_i - \ol{R})(S_i-\ol{S})}{\sqrt{\sum_{i=1}^n (R_i-\ol{R})^2 \sum_{i=1}^n (S_i-\ol{S})^2}} = \frac{\sum_{i=1}^n \ps{R_i - \frac{n+1}{2}}\ps{S_i-\frac{n+1}{2}}}{\sqrt{\frac{n^3-n}{12} \cdot \frac{n^3-n}{12}}} =
            \\
            = \frac{\sum_{k=1}^n \ps{k - \frac{n+1}{2}}\ps{T_k-\frac{n+1}{2}}}{\frac{n^3-n}{12}} = \frac{12}{n^3-n} \sum\limits_{k=1}^n \ps{k - \frac{n+1}{2}} \ps{T_k -\frac{n+1}{2}}
        \end{multline*}

        \item Выведем из предыдущего пункта нехитрыми арифметическими преобразованиями:
        \begin{multline*}
            \rho_S = \frac{12}{n^3-n} \sum\limits_{k=1}^n \ps{k - \frac{n+1}{2}} \ps{T_k -\frac{n+1}{2}} =
            \\
            = \frac{12}{n^3-n} \ps{\sum_{k=1}^n k T_k - \frac{n+1}{2} \sum_{k=1}^n k - \frac{n+1}{2} \sum_{k=1}^n T_k + n \ps{\frac{n+1}{2}}^2} =
            \\
            = \frac{12}{n^3-n} \ps{\sum_{k=1}^n k T_k - n \ps{\frac{n+1}{2}}^2 - \cancel{n \ps{\frac{n+1}{2}}^2} + \cancel{n \ps{\frac{n+1}{2}}^2}} =
            \\
            = \frac{6}{n^3-n} \ps{2 \sum_{k=1}^n k T_k - \frac{n(n+1)^2}{2} - \sum_{k=1}^n k^2 - \sum_{k=1}^n T_k^2 + 2 \frac{n(n+1)(2n+1)}{6}} =
            \\
            = -\frac{6}{n^3-n} \sum_{k=1}^n (k-T_k)^2 + \frac{6}{n^3-n} n(n+1) \ps{\frac{2n+1}{3} - \frac{n+1}{2}} =
            \\
            = -\frac{6}{n^3-n} \sum_{k=1}^n (k-T_k)^2 + \frac{6}{n^3-n} \frac{n^3-n}{6} = 1 - \frac{6}{n^3-n} \sum_{k=1}^n (k-T_k)^2 = 1 - \frac{6}{n^3-n} \sum_{i=1}^n (R_i-S_i)^2
        \end{multline*}

        \item С учётом предыдущего пункта достаточно доказать:
        \[
            2 \sum_{i < j} (j-i) I\{T_i > T_j\} = \sum_{k=1}^n (k-T_k)^2
        \]

        Здесь уже будут хитрые арифметические трюки. Для начала заметим, что:
        \[
            E := \sum_{i < j} i I\{T_i < T_j\} = \sum_{i > j} j I\{T_i > T_j\}
        \]

        Теперь прибавим и вычтем одно и то же:
        \begin{multline*}
            2 \sum_{i < j} (j-i) I\{T_i > T_j\} = 2 \sum_{i < j} (j-i) I\{T_i > T_j\} + 2E - 2E =
            \\
            = 2 \sum_{i < j} (j-i) I\{T_i > T_j\} + 2 \sum_{i > j} j I\{T_i > T_j\} - 2 \sum_{i < j} i I\{T_i < T_j\} =
            \\
            = 2 \sum_{i < j} j I\{T_i > T_j\} + 2 \sum_{i > j} j I\{T_i > T_j\} - 2 \sum_{i < j} i I\{T_i > T_j\} - 2 \sum_{i < j} i I\{T_i < T_j\} =
            \\
            = 2 \sum_{i \neq j} j I\{T_i > T_j\} - 2 \sum_{i < j} i (I\{T_i > T_j\} + I\{T_i < T_j\})
        \end{multline*}

        Если $i \neq j$, то $T_i \neq T_j$, отсюда $I\{T_i > T_j\} + I\{T_i < T_j\} = 1$, получаем:
        \begin{multline*}
            2 \sum_{i < j} (j-i) I\{T_i > T_j\} = 2 \sum_{i \neq j} j I\{T_i > T_j\} - 2 \sum_{i < j} i =
            \\
            = 2 \sum_{j=1}^n j \sum_{i \colon i \neq j} I\{T_i > T_j\} - 2 \sum_{i=1}^n i \sum_{j = 1}^n I\{j > i\} =
            \\
            = 2 \sum_{j=1}^n j \sum_{i=1}^n I\{T_i > T_j\} - 2 \sum_{j=1}^n j \sum_{i=1}^n I\{i > j\}
        \end{multline*}

        Так как в первом слагаемом последнего выражения $T_i$ просто пробегает все значения от $1$ до $n$, а сумма индикаторов просто вырождается в то, сколько подходящих под условие чисел среди чисел от $1$ до $n$, получим:
        \begin{multline*}
            2 \sum_{i < j} (j-i) I\{T_i > T_j\} = 2 \sum_{j=1}^n j \sum_{k=1}^n I\{k > T_j\} - 2 \sum_{j=1}^n j \sum_{k=1}^n I\{k > j\} =
            \\
            = 2 \sum_{j=1}^n j (\cancel{n} - T_j) - 2 \sum_{j=1}^n j (\cancel{n} - j) = 2 \sum_{j=1}^n j^2 - 2 \sum_{j=1}^n j T_j =
            \\
            = \sum_{j=1}^n j^2 + \sum_{j=1}^n T_j^2 - 2 \sum_{j=1}^n j T_j = \sum_{j=1}^n (j-T_j)^2
        \end{multline*}        
    \end{enumerate}
\end{proof}

\begin{proposition} (Свойства коэффициента корреляции Спирмена)
    \begin{enumerate}
        \item Если верна гипотеза $H_0$ о независимости выборок $X$ и $Y$, то:
        \[
            \E \rho_S = 0,\ \ D \rho_S = \frac{1}{n-1}
        \]

        \item $\rho_S \in [-1, 1]$, причём крайние значения достигаются.

        \item Если верна гипотеза $H_0$ о независимости выборок $X$ и $Y$, то распределение $\rho_S$ известно и не зависит от распределений $X$ и $Y$.

        \item Если верна гипотеза $H_0$ о независимости выборок $X$ и $Y$, то:
        \[
            \frac{\rho_S}{\sqrt{D \rho_S}} \xrightarrow{d} N(0, 1)
        \]
    \end{enumerate}
\end{proposition}

\begin{proof}~
    \begin{enumerate}
        \item Получим только значение математического ожидания, значение дисперсии получается аналогично. Вспомним, что при справедливости гипотезы $H_0$ $(T_1, \dots, T_k)$ является случайной перестановкой из $S_n$ вероятности $\frac{1}{n!}$, тогда:
        \[
            \E T_k = \sum_{j=1}^n j P(T_k = j) = \sum_{j=1}^n j \frac{1}{n} = \frac{n+1}{2}
        \]

        Применяя одну из формул для коэффициента Спирмена, получим:
        \begin{multline*}
            \E \rho_S = \E \ps{\frac{12}{n^3-n} \sum\limits_{k=1}^n \ps{k - \frac{n+1}{2}} \ps{T_k -\frac{n+1}{2}}} =
            \\
            = \frac{12}{n^3-n} \sum\limits_{k=1}^n \ps{k - \frac{n+1}{2}} \ps{\E T_k -\frac{n+1}{2}} = \frac{12}{n^3-n} \sum\limits_{k=1}^n \ps{k - \frac{n+1}{2}} \cdot 0 = 0
        \end{multline*}
            
        \item Если обозначить через $\tbr{x, y}$ скалярное произведение в $\R^n$, ввести также обозначения для векторов $R = (R_1 - \ol{R}, \dots, R_n - \ol{R})^T$, $S = (S_1 - \ol{S}, \dots, S_n - \ol{S})^T$, то определение коэффициента корреляции Спирмена можно записать в виде:
        \[
            \rho_S = \frac{\tbr{R, S}}{\sqrt{\tbr{R, R} \tbr{S, S}}}
        \]

        В силу неравенства Коши-Буняковского-Шварца:
        \[
            |\tbr{R, S}| \le \sqrt{\tbr{R, R} \tbr{S, S}} \Ra \rho_S \in [-1, 1]
        \]

        Причём границы достигаются: если $(R_1, \dots, R_n) = (1, \dots, n),\ (S_1, \dots, S_n) = (1, \dots, n)$, то $\rho_S = 1$, если $(R_1, \dots, R_n) = (1, \dots, n),\ (S_1, \dots, S_n) = (n, \dots, 1)$, то $\rho_S = -1$, это мгновенно следует из того факта, что $\ol{R} = \ol{S} = \frac{n+1}{2}$ и:
        \[
            \ps{1 - \frac{n+1}{2}, \dots, n - \frac{n+1}{2}} = \ps{-\frac{n-1}{2}, \dots, \frac{n-1}{2}}
        \]

        \item В случае справедливости гипотезы $H_0$, распределение $(T_1, \dots, T_n)$ не зависит от распределений $X$ и $Y$, уже даже выписывали его явный вид, тогда и распределение $\rho_S$ в силу, например, формулы ниже тоже не зависит:
        \[
            \rho_S = 1 - \frac{6}{n^3-n} \sum\limits_{k=1}^n (k-T_k)^2
        \]

        \item Без доказательства, сначала хочется применить в каком-то виде ЦПТ, но становится понятно, что вытащить сумму независимых одинаково распределённых случайных величин особенно неоткуда, $R_1, \dots, R_n$ (как и $S_1, \dots, S_n$), разумеется, зависимы, хотя бы потому, что не могут принимать двух одинаковых значений. Доказательство можно найти в книге Кендалл Стьюарт <<Статистические выводы и связи>>, по беглому просмотру там нетривиальный вывод на три страницы с использованием чисел Бернулли $B_k = -\frac{1}{k+1} \sum_{j=1}^k C_{k+1}^{j+1} B_{k-j}$.
    \end{enumerate}
\end{proof}

\begin{note}
    Критерий проверки гипотезы $H_0$ с помощью коэффициента Спирмена строится в виде: $\{|\rho_S| > u_{1-\gamma}\}$, где $u_\gamma$ -- $\gamma$-квантиль распределения из пункта 3 последнего утверждения. Критерий можно также построить при помощи нормального приближения из пункта 4.
\end{note}

\subsubsection{Коэффициент корреляции Кендалла}

\begin{note}
    Ещё один коэффициент корреляции, устойчивый к выбросам. Пусть, как и раньше, $X = (X_1, \dots, X_n)$, $Y = (Y_1, \dots, Y_n)$ -- две выборки одинакового размера из непрерывных распределений, $H_0$ -- гипотеза о том, что выборки $X$ и $Y$ независимы.
\end{note}

\begin{note}
    Пусть, как и в коэффициенте корреляции Спирмена, для выборок $X$ и $Y$ введены ранги, в основном нам понадобятся обозначения $T_1, \dots, T_n$.
\end{note}

\begin{definition}
    Пары $(X_i, Y_i)$ и $(X_j, Y_j)$, где $1 \le i < j \le n$, называются согласованными, если $\sign(X_i - X_j) \sign(Y_i - Y_j) = \sign(R_i - R_j) \sign(S_i - S_j) = 1$, то есть у них на обоих компонентах одинаковое отношение порядка.
\end{definition}

\begin{note}
    Идея состоит в следующем: если все пары согласованы или все пары несогласованы, то это не очень похоже на независимость. Обозначим $M$ -- число согласованных пар, $N$ -- число несогласованных пар, не трудно заметить, что $M + N = C_n^2$ -- просто число всех пар. Интересно посмотреть на их разность:
    \[
        T = M - N = \sum_{i < j} \sign(X_i - X_j) \sign(Y_i - Y_j) = \sum_{i < j} \sign(R_i - R_j) \sign(S_i - S_j)
    \]
    Можно записать простые неравенства:
    \[
        -C_n^2 = -M - N \le T \le M + N = C_n^2
    \]
    Причём обе границы достигаются, левая -- если все пары несогласованы, например, в случае $(R_1, \dots, R_n) = (1, \dots, n)$, $(S_1, \dots, S_n) = (n, \dots, 1)$, правая -- если все пары согласованы, например, в случае $(R_1, \dots, R_n) = (1, \dots, n)$, $(S_1, \dots, S_n) = (1, \dots, n)$. Если, наоборот, $T$ близко к нулю, то количество согласованных и несогласованных пар более-менее сбалансировано, что уже похоже на независимость. Поэтому в качестве коэффициента корреляции разумно взять отнормированную версию $T$.
\end{note}

\begin{definition}
    Коэффициентом корреляции Кендалла называется величина
    \[
        \tau = \frac{2}{n(n-1)} T = \frac{2}{n(n-1)} (M - N)
    \]
\end{definition}

\begin{proposition}
    Коэффициент корреляции Кендалла можно записать в следующем эквивалентном виде:
    \[
        \tau = 1 - \frac{4}{n(n-1)} \sum_{i < j} I\{T_i > T_j\}
    \]
\end{proposition}

\begin{proof}
    Число несогласованных пар $N$ равно числу пар $\{(i, j) \colon i < j,\ T_i > T_j\}$, поэтому можем записать:
    \[
        \tau = \frac{2(M-N)}{n(n-1)} = \frac{2(M+N)}{n(n-1)} - \frac{4N}{n(n-1)} = 1 - \frac{4}{n(n-1)} \sum_{i < j} I\{T_i > T_j\}
    \]
\end{proof}

\begin{proposition} (Свойства коэффициента корреляции Кендалла)
    \begin{enumerate}
        \item Если верна гипотеза $H_0$ о независимости выборок $X$ и $Y$, то:
        \[
            \E \tau = 0,\ \ D \tau = \frac{2(2n+5)}{9n(n-1)}
        \]

        \item $\tau \in [-1, 1]$, причём крайние значения достигаются.

        \item Если верна гипотеза $H_0$ о независимости выборок $X$ и $Y$, то распределение $\tau$ известно и не зависит от распределений $X$ и $Y$.

        \item Если верна гипотеза $H_0$ о независимости выборок $X$ и $Y$, то:
        \[
            \frac{\tau}{\sqrt{D \tau}} \xrightarrow{d} N(0, 1)
        \]
    \end{enumerate}
\end{proposition}

\begin{proof}~
    \begin{enumerate}
        \item Получим только значение математического ожидания, значение дисперсии получается аналогично. Воспользуемся тем, что знаем распределение $(T_1, \dots, T_k)$ в случае справедливости гипотезы $H_0$:
        \[
            \E \tau = \E \ps{1 - \frac{4}{n(n-1)} \sum_{i < j} I\{T_i > T_j\}} = 1 - \frac{4}{n(n-1)} \sum_{i < j} \E I\{T_i > T_j\}
        \]

        Распишем последнее математическое ожидание:
        \[
            \E I\{T_i > T_j\} = P(T_i > T_j) = \frac{|\{(r_1, \dots, r_n) \in S_n \colon r_i > r_j\}|}{|\{(r_1, \dots, r_n) \in S_n\}|} = \frac{\frac{1}{2} C_n^2}{C_n^2} = \frac{1}{2}
        \]

        В результате получим:
        \[
            \E \tau = 1 - \frac{4}{n(n-1)} \sum_{i < j} \frac{1}{2} = 1 - \frac{4}{n(n-1)} C_n^2 \frac{1}{2} = 1 - 1 = 0
        \]

        \item Мгновенно следует из того, что $-C_n^2 \le T \le C_n^2$, причём крайние значения достигаются, что поняли в одном из замечаний выше.

        \item Следует из того, что в случае справедливости гипотезы $H_0$ знаем распределение $(T_1, \dots, T_k)$ и формулы:
        \[
            \tau = 1 - \frac{4}{n(n-1)} \sum_{i < j} I\{T_i > T_j\}
        \]

        \item Без доказательства.
    \end{enumerate}
\end{proof}

\begin{note}
    Критерий проверки гипотезы $H_0$ с помощью коэффициента Кендалла строится в виде: $\{|\tau| > u_{1-\gamma}\}$, где $u_\gamma$ -- $\gamma$-квантиль распределения из пункта 3 последнего утверждения. Критерий можно также построить при помощи нормального приближения из пункта 4.
\end{note}

\begin{note}
    Сравним ещё коэффициенты корреляции Спирмена и Кендалла, воспользовавшись формулами:
    \begin{align*}
        & \rho_S = 1 - \frac{12}{n^3-n} \sum\limits_{i<j} (j-i) I\{T_i > T_j\}
        \\
        & \tau = 1 - \frac{4}{n(n-1)} \sum_{i < j} I\{T_i > T_j\}
    \end{align*}
    Видим, что коэффициент Спирмена гораздо более чувствителен к различиям рангов в несогласованных парах, так как он считает не просто количество таких пар, а их взвешенное количество с весами $j-i$, то есть различия в рангах. Тем не менее, при справедливости гипотезы $H_0$ коэффициенты Спирмена и Кендалла очень сильно скоррелированы:
    \[
        \corr(\rho_S, \tau) = \frac{2(n+1)}{\sqrt{2n(2n+5)}} \xrightarrow[n \to \infty]{} 1
    \]
\end{note}